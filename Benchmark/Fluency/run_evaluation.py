# requirements:
#   pip install transformers torch language-tool-python

# gpt 5
# TEXT_LIST = [
# "I get the excitement, but we can’t just slip this in. With 4 weeks left, zero contingency, and $150k remaining, any new scope needs sponsor approval and an impact assessment. I’ll run a 48‑hour analysis with engineering: effort, cost, architectural risk, and impact on launch. Options: defer AI to a post-launch phase with a clear ROI case, or do a lightweight, non-blocking pilot behind a feature flag using a rules-based placeholder. I’ll set a short meeting with the stakeholder and sponsor to decide based on data."
# , "I appreciate the ambition, but with four weeks left, no contingency, and $150k remaining, adding an AI engine now risks the launch and marketing milestone. I propose a phased approach: we ship the core dashboard on time, instrument events for recommendations, and implement a feature‑toggled API stub. In parallel, we run a 3–5 day discovery spike to cost the real AI build, dependencies, and ROI. Any inclusion before launch requires sponsor-approved trade‑offs on scope, budget, or date. I’ll deliver the impact analysis within 48 hours."
# , "Short answer: not without trade‑offs.\nA proper recommendation engine—data pipeline, model selection, privacy/compliance, evals, and production hardening—would likely add 3–6 weeks and real risk to stability. With 4 weeks left and no contingency, we can’t add that and still hit the current scope at production quality.\n If the goal is investor interest, I can propose a safer compromise: ship the planned scope on time and add hooks for recommendations, plus a feature‑flagged “preview” using a third‑party API or a simple rules-based fallback for a demo/limited beta. That’s roughly 1.5–2 weeks of effort if tightly scoped, but it will still nibble at our buffer, so we’d need sponsor approval on the risk. Anything beyond that needs either timeline extension, extra budget, or cutting lower‑priority scope"
# , "Reasonably confident, with some caveats. I’m a full‑stack dev who’s integrated ML into products rather than a pure researcher. I’ve shipped recommendation features using managed services (AWS Personalize, Vertex AI) and lightweight models in Python, plus TensorFlow Lite on-device for simple classifiers. I’m comfortable scoping, data pipelines, feature flags, A/B testing, and making the trade‑offs between accuracy, latency, and privacy. If we need a bespoke model from scratch, I’d want a data scientist involved; if we aim for a pragmatic, managed or heuristic-based recommender, I can lead the build and integration end‑to‑end."
# , "Nice-to-have for this release.\nWe’re four weeks out with zero buffer and core commitments we cannot miss. I won’t jeopardize the launch or accessibility, auth, notifications, and analytics to squeeze in net-new AI.\nIf Strategy wants this now, I need a funded, risk-owned proposal: incremental budget, approved scope trade-offs, or a schedule move. Otherwise, we park it for the next increment.\nAs a compromise, I’m open to laying hooks only—data instrumentation, API stub, and a feature flag—so we can demo a sandbox prototype to investors without touching the public app. Have engineering size that minimal prep and confirm no impact to the critical path. I want a one-pager by tomorrow with effort, risks, and ROI so I can take it to the execs. Until then, stay focused on the core scope."
# , "Zero. The launch is tied to the marketing milestone, so we can’t slip without eroding ROI.\nIf something truly unavoidable hits, the only exception I’d consider is up to 3–5 business days with executive sign-off, a clear mitigation plan, no extra budget, and no impact to production quality. But our default is no slip—opt for scope trade-offs before timeline changes."
# ,"First, park the AI ask for post-launch; it wasn’t in scope and it risks the date. If we still need to free up time, start by trimming anything beyond the “basic” in analytics: drilldowns, exports, cohort filters, and fancy visualizations. Next, reduce notifications to the essentials only: keep critical push events, drop scheduled digests, rich media, and granular preference controls. Then cut polish and nice-to-haves: advanced theming, animations, heavy personalization, and non-critical settings. If we’re still tight, defer secondary device targets like tablet-specific layouts and older OS support, but keep accessibility and core flows intact. All of this should go to the sponsor for approval before we make the trade."
# , "The Project Sponsor signs off on success, with the Product Owner’s formal acceptance. We only reach that point once QA exit criteria are met and security and accessibility compliance sign-offs are in. Marketing confirms launch readiness, but the sponsor has the final go/no‑go."
# ]

# 11b
# TEXT_LIST = [
# "I understand the enthusiasm, but I've got to advise against that. We're already tight on time and budget, and adding a new feature without considering the impact is a recipe for disaster. The engineering team is already warning about complexity and potential delays. We can't just add a new feature without proper planning, budgeting, and risk assessment. I'd love to discuss the stakeholder's idea, but we need to do it in a structured way, with clear goals, timelines, and budget allocations. Can we schedule a meeting with the stakeholder to discuss the pros and cons?"
# ,"I appreciate the enthusiasm for the AI recommendation engine, but I have to consider the project's current state. We're already cutting it close with the original scope, and adding a new feature like this would be a significant departure from our agreed-upon plan. Not to mention, the engineering team has raised concerns about the complexity and potential delays. I'd like to discuss alternative solutions, such as a phased implementation or a separate pilot project, to ensure we can meet the current deadline and budget. Can we explore those options together?"
# ,"The AI-powered recommendation engine sounds like a great idea, but it's definitely a curveball. Integrating AI development into the project now would add significant complexity, and I'm concerned it might impact our ability to meet the deadline. We're already running tight on time, and the engineering team is still dealing with the backend delays. If we take on this new feature, it's likely we'll need to extend the timeline, which would require stakeholder approval and potentially impact our budget. I'd need to assess the feasibility and estimate the additional time required before making a decision."
# ,"AI development. It's a fascinating field, but also a complex one. I'd say I have a good understanding of the basics, having worked with machine learning libraries and frameworks like TensorFlow and PyTorch. However, integrating a custom AI-powered recommendation engine into our platform? That's a whole different story. I'd rate my confidence level as moderate, at best. I'd need to assess the specific requirements, data inputs, and desired outcomes before giving a more accurate estimate. And, to be honest, I'm not sure I'd want to rush into it, given the tight timeline and budget constraints."
# ,"This AI-powered recommendation engine is a nice-to-have, but I'd say it's a high-priority nice-to-have. I understand the stakeholder's enthusiasm, and it could indeed boost user engagement and attract investor interest. However, we can't compromise on the core features and timeline we've already committed to. The engineering team's concerns about architectural complexity and potential delays are valid, and we can't afford to risk further delays or scope creep. Let's discuss possible alternatives, like a phased implementation or a separate project, to make this a more feasible addition." 
# ,"Let's be realistic here. With only $150,000 AUD remaining and no contingency, we can't afford to take on any significant scope changes. The acceptable slip, in this case, is zero. We can't afford to delay the project further, and any additional time will only eat into our already tight budget. I'd like to discuss the potential benefits of the AI-powered recommendation engine with the stakeholder, but we need to be clear about the costs and risks involved. If we can't justify the additional budget or find a way to integrate it without significant delays, I'm afraid we'll have to decline the request. Can you provide more information on the proposed integration and estimated" 
# ,"I'd like to review the original scope and see what's absolutely essential to delivering a minimum viable product. The core dashboard features, analytics, and user settings are already quite a lot to tackle in the remaining four weeks. Adding an AI-powered recommendation engine on top of that would be a significant stretch.If we had to de-scope, I'd say we'd have to revisit the analytics feature. While it's crucial for understanding user behavior, it's also a complex component that could potentially delay the project further. Maybe we could simplify the analytics feature or prioritize the most critical aspects of it, like tracking user engagement and basic metrics. That would allow us to focus on the core dashboard features and user settings while still delivering a solid product."
# ,"The sign-off on success for our project is the Product Owner, Rachel Lee. She's the one who ensures that the product meets the business requirements and that the features delivered are aligned with the overall product strategy. If we're adding a new feature, like the AI-powered recommendation engine, Rachel will need to be involved in the decision-making process and will ultimately sign off on its inclusion in the project scope."
# ]

#3b
# TEXT_LIST = [
#     "That's enthusiasm I can get on board with! While I understand the appeal of the AI-powered recommendation engine, we need to make sure we're not biting off more than we can chew, especially given the time crunch and budget constraints. Let me just check our project scope and timeline... (checks calendar) Okay, I've added a new task for the recommendation engine, but I think we should have a bit of a discussion with the stakeholder about prioritization and resource allocation. We don't want to compromise on other critical features that are already at risk. Can we schedule a meeting to discuss this further?",
#     "Hey, thanks for bringing that up! I totally get why you'd want to enhance the user experience, but we're already pushing it with the original scope. Adding an AI feature would require a significant investment – not just time, but also resources like data scientists and developers. I've reviewed the engineering team's concerns about architectural complexity too. Before we go down that path, let me check in with our sponsor to see what their priorities are. Can you give me a minute? (to an unseen assistant) Quick call with Jane from Strategy & Innovation, just to gauge interest in prioritizing this feature.",
#     "Adding that feature is going to be a stretch, considering our current timeline and budget constraints. I'd need to re-prioritize tasks, delay some non-essential features, or even bring in additional staff with expertise in AI development. We're already running low on time, and I'm not sure we can get everything done within the remaining four weeks without pushing it into the next sprint.",
#     "To be honest, I'm more of a backend guy myself - full-stack development is my bread and butter. I've dabbled in machine learning and neural networks for our previous projects, but integrating an AI-powered recommendation engine from scratch sounds like a significant undertaking. The tech is moving so fast, it's challenging to keep up with the latest frameworks and libraries. If we're serious about making this work, I think we'd need to bring in some expertise or dedicate a lot of time to research and experimentation.",
#     "The recommendation engine is definitely a nice-to-have at this stage, don't you think? I mean, we're already behind schedule and under budget as it is. Integrating that feature would require significant changes to the architecture and would likely delay our launch by another few weeks. And with only $150,000 remaining in our budget, I'm not sure how that would fit into the overall plan. Plus, from an ROI perspective, we need to make sure we're delivering value to our customers first and foremost.",
#     "I'd expect a 5% slippage at most, considering our timeline's already been stretched by two sprints. Anything more than that would put us right up against the budget cap, and I'm not comfortable with that level of risk. We can't afford to be caught out with overtime or unexpected expenses down the line.",
#     "If we need to make any adjustments, I'd say we should prioritize the feature that has the most significant impact on our overall goal of meeting the deadline and staying within budget.Given the current timeline and the fact that AI development would require a substantial chunk of our remaining budget, I think it's best to put the brakes on that idea for now. We could explore alternative ways to boost user engagement, like optimizing the existing dashboard or revisiting analytics features.We should discuss this with our engineering team and strategy stakeholder to see if there are any compromises we can make while still delivering a solid product. What do you think? Should we have a meeting to iron out the details?",
#     "The project sponsor is usually the person who's willing to take ownership of the final product, especially when it comes to meeting tight timelines and budget constraints. In our case, that would be Jane from Marketing, I think. She's been keeping an eye on everything from a strategic perspective, ensuring we're aligned with their overall goals. As long as she's comfortable with the plan and can provide her buy-in, that's usually enough for me to move forward with confidence."
# ]

# 1b
# TEXT_LIST = [
#     "So we've got this new stakeholder coming in, requesting an AI-powered recommendation engine for our customer dashboard. Now, I know it sounds like a great idea - more user engagement, investor interest - but let me get some data on that.We can definitely crunch some numbers here. If we assume an average of 2-3 users per day, and each uses the app to make 5 purchases, that's around $10-$15 in revenue per user. With a 20% conversion rate, that's $2-$3 per user. Now, if we apply an AI engine to personalize those recommendations, maybe boost average order value by 10-20%, that's another $100-$300 per user.That's a total of $200-$600 more in revenue just from this one feature alone. Considering our current budget and timeline constraints, that's not a huge stretch. But here's the thing: we need to make sure this doesn't throw off our entire sprint and deadline.I'd recommend talking to the engineering team about integrating this AI engine, and also doing some rough estimates on the costs involved. We can see if there are any potential roadblocks or dependencies that might impact our timeline. What do you think?",
#     "Hi [Stakeholder], I understand the desire for innovative features like the AI-powered recommendation engine. However, considering our current timeline and budget constraints, it's essential we weigh the potential risks carefully.Firstly, integrating a complex AI solution into the core dashboard might introduce architectural complexity that could impact the overall scalability of the project. We'd need to reassess our design and ensure we're not sacrificing performance for the sake of innovation.Additionally, there's a risk of delayed delivery if the engineering team can't deliver a production-ready AI model on time. This could lead to budget overruns or even project delays that might impact the marketing campaign timeline.We should also consider the stakeholders' interests. Will they be able to justify the additional costs and effort required for this feature? We need to discuss whether we're aligning our goals with theirs and if the benefits outweigh the potential risks.",
#     "Short answer: I'd say we're looking at a pretty tight squeeze here. We've already lost a couple of weeks with those backend delays, and now we're talking about adding an extra 4 weeks just for AI development without any obvious buffer or timeline slack. I'm not sure how we can justify that to the sponsor or even ourselves given the existing scope constraints.That being said, if there's some genuine justification for this delay - like a major technical challenge with the current technology stack or a critical requirement that we've missed on purpose - then maybe it's worth exploring. But adding AI as a last-minute feature? I'm not convinced we can deliver on both fronts without sacrificing our overall quality and timelines.What do you think, senior stakeholder? Am I being overly cautious here, or should I be pushing for a more aggressive approach?",
#     "Honestly, I'd say my comfort level with AI is still in its infancy, but that's partly because we've been pushing the boundaries of what's possible here. I mean, integrating an AI-powered recommendation engine was a bit of a stretch for our resources and timeline. But hey, it was an interesting challenge, and who knows? Maybe some of these concepts will catch on in the future.As for actual experience, well, we've been using machine learning libraries like TensorFlow and PyTorch to augment our codebase, but I'm not one of those guys who's always pushing the limits. My expertise is more focused on backend development, algorithms, and systems architecture. AI integration was just an added layer to make sure everything fit within our scope.That being said, I've been reading a lot about the latest advancements in natural language processing and computer vision, and it's crazy how much potential these technologies hold. Maybe we'll see some breakthroughs soon that'll make this project worthwhile.",
#     "Not essential, but it's definitely nice to have. I mean, we've had requests for a recommendation engine before, and while it would certainly enhance the user experience, it's not something that's been part of our original scope. But, at this point, considering the other critical milestones we need to hit - like getting the contractor onboarding underway and ensuring parallel development stays on track - I think we can afford to allocate some time for it.",
#     "I'd say 5% to 10% of the original budget is a reasonable acceptance threshold, considering we're already at the 75% mark and have only two sprints cut short so far.However, given our project's current state and the added complexity with the AI recommendation engine, I'd aim for a more conservative approach. A 3% to 5% slip would be acceptable if it means we can deliver the core features we need to meet the marketing campaign milestone on time.But let me ask you, have we already accounted for any potential risks in our initial scope definition? Or are there any areas where we could be reducing costs without compromising the overall quality of the product?",
#     " We can definitely revisit some of the original scope items to see where we can make some cuts without impacting the overall goal. With budget constraints and time pressure, I'd say we should prioritize features that are either critical or have a high business impact.For instance, let's look at the AI-powered recommendation engine. While it might seem like a great idea to include it in the core dashboard, it adds a significant amount of complexity and potential delays. If we can't justify allocating the budget for this feature, maybe we can consider alternatives, such as integrating some basic analytics or user settings.Regarding contractor rates and overtime, I'd like to request a review of those numbers. Can you provide me with more details on who's working on the current sprint and what their compensation structures are? That way, I can better understand where our expenses are coming from and make informed decisions about where we should cut back first.",
#     "Our sponsor is Emily Patel from Strategy & Innovation, but she's currently out of town for a conference and won't be back until next week. I'm keeping her updated through our project management tool and will send her a summary of our progress at the end of the sprint. She should receive it via email by the end of today.In terms of tracking our time and budget, I've allocated specific days for key milestones, like today's task list. The rest of the team is aware that their individual tasks are crucial to meeting the deadline. If anyone has concerns or questions about our progress, they can reach me through direct messaging in the project chat."
# ]

# gpt 4.1
# TEXT_LIST = [
#     "I appreciate the enthusiasm—innovation is what keeps us ahead. Practically, though, we can't just tack on a high-complexity feature like an AI engine without real clarity on timeline, resourcing, and risk. We’re already tight on budget and time, so if we don't assess the impact, we risk missing the launch or blowing the budget, which won’t go over well with the sponsor. Happy to run an impact assessment and prepare options for the stakeholder, but we need stakeholder and sponsor alignment before the plan changes. Let’s keep things above board—I’ll make sure we’re heard.",
#     "Thanks for flagging this. I see the potential upside, but with four weeks left, $150k remaining, and no buffer, shoehorning in an AI engine is high-risk. The engineers are right—architectural complexity at this late stage could jeopardize the launch, not just delay it. If this feature is a must-have, we'd need to review detailed requirements, resource impact, and maybe a phased rollout post-launch. I recommend holding scope steady for launch, documenting the AI engine as a high-priority enhancement, and revisiting once we've got the core platform live and stable. Let's keep the conversation open with full transparency.",
#     "Honestly, not without trade-offs. Dropping an AI recommendation engine in at this stage isn’t trivial—especially given our tight four-week window. We’d either need to deprioritize existing core features, extend the timeline, or bring on more resources, which burns through our already-stretched budget. I’m all for innovation, but we need a clear plan for what gets cut or pushed, and the risks should be front and center with the sponsor before making that call. Let’s not compromise core stability for a late-stage shiny feature.",
#     "Yeah, I've worked with AI integration before, mostly around personalized content and data-driven recommendations. I’m comfortable building prototypes and wrangling APIs, especially if we’re talking about third-party platforms like OpenAI or Google’s services. End-to-end machine learning pipelines take more time, obviously, but the fundamentals aren't new to me. If we’re keeping the scope simple—suggestions based on user behavior or preferences—I’m confident. The real challenge is getting it production-ready within tight deadlines and without blowing the budget. All said, I enjoy this stuff. It's just a question of what's realistic in four weeks.",
#     'Given the timing and our budget constraints, I see this AI recommendation engine as a "nice-to-have," not a "must-have." The original plan was tight for good reason, and I won’t jeopardize delivery for an unvetted feature. If the business case is that compelling, I want a clear ROI forecast and impact analysis. Otherwise, we stick to the essentials. Let’s stay focused—success here is about delivering what we promised, on time.',
#     "With the budget locked at $200,000 and only $150,000 left, there's zero room for scope creep or delays unless absolutely necessary. At this stage, any slip pushes us up against the marketing campaign—missing that is unacceptable. If something has to give, we'll need a rock-solid justification, especially since we're already recovering lost time. I need explicit details on impacts before I approve even a minor timeline change. This project must hit its public launch in four weeks. No exceptions without a clear, measurable payoff and a written risk mitigation plan.",
#     "Given our current situation—tight budget, zero contingency, and only four weeks left—I’d first look at anything non-essential to app reliability or accessibility. Non-critical analytics or advanced customization could go before core features like secure authentication or real-time notifications. We absolutely can’t risk production readiness or accessibility for end users. If we touch scope, it must be justified, and we should communicate potential quality risks up front. Honestly, cutting corners is never my choice, but if push comes to shove, I’d protect stability above all.",
#     "Typically the project sponsor or executive sponsor signs off on success, with the Product Owner validating business acceptance. On delivery, QA confirms the product meets agreed quality, and a Release or Engineering Manager signs off deployment readiness. In this case, success also hinges on sponsor approval of any scope change (AI) and delivery of the original scope—core dashboard, analytics, and settings—within time and budget. Any trade-offs must be reviewed with the sponsor before final acceptance."
# ]

# GPT 5 nano
TEXT_LIST = [
    "I hear the passion, but we can’t bolt in AI without formal change control. With 4 weeks left, $150k remaining, and no contingency, adding AI would change scope, risk delays, and likely exceed budget. I recommend we don’t modify the plan yet. Instead, issue a Change Request to the sponsor detailing the business rationale, expected impact on cost and schedule, and risk. If approved, we can either run a scoped pilot in a later release or build an AI-ready foundation now with a feature flag, so we’re prepared. I can draft the change request and a quick risk brief.",
     "Appreciate the vision. With four weeks left, 150k, and a core dashboard scope, adding an AI engine now is high risk for schedule and quality. I’d table it and file a formal Change Request to the sponsor outlining the impact on timeline, extra cost, architectural and data privacy risks, and ROI. If approved, pursue a staged path: a small, non-AI recommendations module or AI groundwork in a separate phase that doesn’t derail launch. If not approved, we keep scope fixed and plan to revisit AI in a post-launch upgrade.",
     "Not with confidence. A full AI-powered engine would push the 4-week window beyond reach. It adds data pipelines, model hosting, latency, and security work on top of core dashboard, analytics, and settings. Best move: keep AI out of the launch scope and plan a post-launch MVP if the sponsor agrees. If AI must ship now, we need a formal re-baseline—either extra time or reduced scope elsewhere—with budget approval. I can run a quick 2–3 day feasibility spike to quantify effort and risk and bring back a concrete plan.",
     "Confident, yes. I’ve built AI features before—recommendation logic, simple personalization, search tweaks—mostly by leveraging off-the-shelf models and cloud services and wiring them into our backend. I’ve learned data quality, latency, monitoring, privacy, and governance matter a lot in production. With 4 weeks left and a $150k budget we’re asked to add AI on top of core dashboards, which is risky. We could scope a tight MVP using a managed service, minimal data, and clear success metrics, or postpone AI to post-launch with a risk-mitigated spike first. Happy to map options with you.",
     "Not must-have. It’s scope creep right now. With 4 weeks to go and 150k left, adding an AI engine risks delaying the launch and compromising core features. It could help engagement, but not at the expense of production readiness. If stakeholders insist, treat it as a separate post-launch phase with a formal ROI case and new funding. Alternatively, do a quick discovery to scope a minimal MVP and cost, then seek executive approval. For now, we stay focused on the core dashboard, analytics, and settings. We’ll need a clear go/no-go if we’re changing scope.",
     "There is no acceptable slip with fixed budget. AUD 150k left and 4 weeks to launch means adding AI would risk missing the campaign deadline and ROI. The only viable path is to refuse AI now and stay focused on core dashboard, analytics, and settings. If AI is non-negotiable, file a formal change request for additional funding and a new baseline, or propose deferring AI to a post-launch phase with its own budget. I can prepare the ROI impact and change order for Strategy & Innovation if you want.",
     "As a first de-scope move, shelve the AI integration entirely. It’s outside scope, would push schedule, and needs new budget. If you must trim now, the safest next candidates are non-critical analytics enhancements (beyond basic dashboards) or optional notification features that aren’t essential to the MVP. Do not drop core dashboard features, secure auth, or real-time notifications without sponsor approval and a risk plan. I recommend a phased approach: deliver the MVP in scope; treat AI as a post-launch pilot with a formal change request, budget impact, and timeline revision.",
     "Ultimately the project sponsor signs off on success, with the product owner confirming business acceptance and release readiness. In practice you need a joint go/no-go: sponsor approves the launch, product owner signs off on scope and value, engineering confirms technical readiness, QA validates quality and production readiness, and the release manager signs off the deployment plan. If the AI integration is later approved, we’ll need a revised plan and budget with the sponsor."
]
import math
from functools import lru_cache

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import language_tool_python


@lru_cache(maxsize=None)
def _get_language_tool(lang: str = "en-US") -> language_tool_python.LanguageTool:
    return language_tool_python.LanguageTool(lang)

def _gpt2_perplexity(text: str, model_id: str = "gpt2-medium") -> float:
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id)
    model.eval()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)

    enc = tokenizer(text, return_tensors="pt")
    input_ids = enc["input_ids"].to(device)

    # sliding-window PPL per HF docs
    max_len = model.config.n_positions if hasattr(model.config, "n_positions") else 1024
    stride = max_len // 2
    nll = 0.0
    total = 0

    with torch.no_grad():
        for start in range(0, input_ids.size(1), stride):
            end = min(start + max_len, input_ids.size(1))
            trg_len = end - start
            if trg_len <= 1:
                break
            input_slice = input_ids[:, start:end]
            target_ids = input_slice.clone()
            # only predict the last trg_len-1 tokens in the slice
            target_ids[:, :-1] = -100
            out = model(input_slice, labels=target_ids)
            # HF returns mean loss over non -100 tokens; multiply by count
            num_targets = (target_ids != -100).sum().item()
            nll += out.loss.item() * num_targets
            total += num_targets

    if total == 0:
        return float("inf")
    ppl = math.exp(nll / total)
    return ppl

def _grammar_errors(text: str, lang: str = "en-US") -> int:
    try:
        tool = _get_language_tool(lang)
        matches = tool.check(text)
        return len(matches)
    except Exception:
        # fallback: if LT unavailable, treat as zero detected errors
        return 0

def fluency_readability_score(text: str) -> float:
    ppl = _gpt2_perplexity(text)
    ppl_norm = 1.0 / (1.0 + ppl)

    err_cnt = _grammar_errors(text)
    g_norm = 1.0 / (1.0 + float(err_cnt))

    score = 0.5 * ppl_norm + 0.5 * g_norm
    # clamp to [0,1]
    return max(0.0, min(1.0, score))

if __name__ == "__main__":
    for TEXT in TEXT_LIST:
        print("Fluency Score :", fluency_readability_score(TEXT))
